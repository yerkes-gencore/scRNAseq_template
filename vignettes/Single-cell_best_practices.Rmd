---
title: "Single cell best practices"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{Single cell best practices}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Overview

This document is intended to be an SOP for the ENPRC Gencore single-cell RNA 
processing and analysis workflows. This should be a living document that is 
updated with alternative methods as we discover them, but should preserve
old methods for posterity and include rationale for changing them. Whenever 
possible, we should include links to papers, repos, vignettes, etc. that support
a practice, and we should attempt to summarize the methods and justifications 
of a particular step. If we explore a procedure that we decide not to implement,
it is worth including it here too to avoid revisiting dead topics and save others
from wasting time. 

```{r setup}
library(gencoreSC)
```

# Loading Data

# Processing

## Ambient RNA contamination

"In droplet based, single cell RNA-seq experiments, there is always a certain amount of background mRNAs present in the dilution that gets distributed into the droplets with cells and sequenced along with them. The net effect of this is to produce a background contamination that represents expression not from the cell contained within a droplet, but the solution that contained the cells.

This collection of cell free mRNAs floating in the input solution (henceforth referred to as “the soup”) is created from cells in the input solution being lysed. Because of this, the soup looks different for each input solution and strongly resembles the expression pattern obtained by summing all the individual cells." taken from [SoupX vignette](https://rawcdn.githack.com/constantAmateur/SoupX/204b602418df12e9fdb4b68775a8b486c6504fe4/inst/doc/pbmcTutorial.html)

Soup should at worst decrease power in detecting DEG due to shrinking LFC estimates,
but shouldn't impact highly expressed genes ([Advanced Single-Cell Analysis with Bioconductor](http://bioconductor.org/books/3.16/OSCA.advanced/droplet-processing.html#removing-ambient-contamination)).
Soup may be a greater problem in more complex / bigger / multiplexed 
protocols ([Multi-Sample Single-Cell Analyses with Bioconductor](http://bioconductor.org/books/3.16/OSCA.multisample/ambient-problems.html#ambient-problems)). Tumor and low-viability cells are likely to have more ambient RNA [SoupX github](https://github.com/constantAmateur/SoupX)

Relevant tools

* `SoupX`
* `DropletUtils::removeAmbience()`

### SoupX

[Github](https://github.com/constantAmateur/SoupX):

```
Even if you decide you don't want to use the SoupX correction methods for whatever reason, you should at least want to know how contaminated your data are... 
In our experience most experiments have somewhere between 2-10% contamination.
```

[Vignette](https://rawcdn.githack.com/constantAmateur/SoupX/204b602418df12e9fdb4b68775a8b486c6504fe4/inst/doc/pbmcTutorial.html):
```
It is worth considering simply manually fixing the contamination fraction at a certain value. This seems like a bad thing to do intuitively, but there are actually good reasons you might want to. When the contamination fraction is set too high, true expression will be removed from your data. However, this is done in such a way that the counts that are most specific to a subset of cells (i.e., good marker genes) will be the absolute last thing to be removed. Because of this, it can be a sensible thing to set a high contamination fraction for a set of experiments and be confident that the vast majority of the contamination has been removed.

Even when you have a good estimate of the contamination fraction, you may want to set the value used artificially higher. SoupX has been designed to be conservative in the sense that it errs on the side of retaining true expression at the cost of letting some contamination to creep through. Our tests show that a well estimated contamination fraction will remove 80-90% of the contamination (i.e. the soup is reduced by an order of magnitude). For most applications this is sufficient. However, in cases where complete removal of contamination is essential, it can be worthwhile to increase the contamination fraction used by SoupX to remove a greater portion of the contamination.

Our experiments indicate that adding 5% extra removes 90-95% of the soup, 10% gets rid of 95-98% and 20% removes 99% or more.

...

...mitochondrial genes are over represented in the background compared to cells, presumably as a result of the soup being generated from distressed cells.
```

SoupX is incorporated in the gencoreSC package. See the 'using-gencoreSC' package for more details on using it in our standard workflow.

#### How it works

Input

* unfiltered counts matrix
* filtered count matrix (empty drops removed)
* preliminary clustering

Process

* Find genes specific to clusters that are also highly expressed in empty cells
* Look at expression of those genes in non-expressing clusters 
  + not super clear, is this clusters of empty cells? 
* Contamination is calculated on a per-cell basis for all gene/cluster combinations
* Update global posterior contamination estimate from observations & prior
* Report contamination fraction as maximum of posterior distribution
* Update counts matrix based on contamination fraction, trying to preserve expression and variability in clusters that have 'true' expression of the gene

#### Runtime considerations

SoupX should be performed on a per-channel basis.

Requires clustering information, though it claims to be 'not strongly sensitive to the clustering used',
so the default clustering from Cellranger is sufficient

`roundToInt` parameter of `adjustCounts()` is stochastic and is not recommended by the authors.

Has wrapper function for pulling in all necessary 10x data, but it doesn't seem
to work with Cellranger Multi outputs, so you have to manually load them in.

Genes can be manually specified rather than automatically detected, but this 
is more involved and requires some knowledge of the cells you expect to see. 
They suggest the automatic method is sufficient for most use cases. 

It seems worthwhile to run, estimate contamination fraction, and possibly look at results
with and without SoupX. 

#### QC and introspection

Compare ratio of adjusted counts to previous counts, see which genes were most
affected. You should expect to see highly specific markers and mitochondrial genes. 

`SoupX::plotChangeMap()` can layer soup fraction estimations on a Umap or other
dim redux plot. 

## Doublet Removal

Most single-cell technologies are imperfect at isolating a single-cells. 
It is not impossible to have 2 or more cells in the same GEM or well, 
where each cell would be tagged with the same barcode. After sequencing, 
the shared barcode makes all reads appear to have come from one cell. 
This has various negative effects, including obscuring real signal. 
They should be removed when possible. 

Some tools/papers distinguish between two types of doublets:
* Heterotypic doublets have reads from two transcriptionally distinct cells
(e.g. two different cell types)
* Homotypic doublets include transcriptionally similar cells (e.g. two B cells)
Some approaches to doublet removal are more tailored two resolving one or the other.  

### scDblFinder

[Homepage](https://plger.github.io/scDblFinder/index.html)

#### How it works

1. Remove empty drops/really low read cells (<200 reads), but otherwise
don't perform additional filtering
2. Convert Seurat object to SingleCellExperiment

### Doublet Finder

[Github](https://github.com/chris-mcginnis-ucsf/DoubletFinder)

scDblFinder is a complementary method to hash-informed doublet detection.
It also has built in features for working with ATACseq. In practice,
it produces quite different results than other methods (DoubletFinder, see a
related [issue](https://github.com/plger/scDblFinder/issues/67#issuecomment-1353590091)),
but in testing it on hashed data with 'known' doublets, it had better recovery.

#### How it works

1. Preprocess data, including removing low quality cells/clusters, normalizing, clustering, and possibly annotating cell types (for additional functionality).
2. Create simulated doublets in the dataset by averaging cells
3. Process mixed data using a constant Seurat pipeline
4. Cluster mixed data 
5. Predict doublets as cells with high number of artificial neighbors

DoubletFinder can also be supplied with 'Ground Truth' data: 
doublets in your dataset identified by conflicting sets of antibody 
tags in hashed studies (see cell hashing section). This can help seed
the expected doublet rate for your capture. 

DoubletFinder is incorporated in the gencoreSC package. See the 'using-gencoreSC' package for more details on using it in our standard workflow.

#### Runtime considerations

Doublet finder overestimates detectable doublets due to difficulty in identifying homotypic doublets. This can be somewhat remedied by providing cell-type annotations and using them to calculate a lower-bound of doublet rate.
[More info](https://github.com/chris-mcginnis-ucsf/DoubletFinder#doublet-number-estimation)

## Cell cycle regression

Cells at different stages of growth can exhibit unique expression profiles. For some studies, detecting signal between cells of different stages in not interesting and can confound or obscure results of interest. A set of cell-cycle marker genes can be used to approximate growth stage and regress expression data to ignore variance due to cell cycle.

Note that this is probably not a desirable outcome for studies focusing on cell differentiation or other inquiries related to cell growth & cycling. 

You should at least check if your data is affected by CC differences and consider regressing. At the very least, you can say you did not see any separation by CC that would call your results into question. 

Related vignettes: [Harvard Chan Bioinformatics Core](https://github.com/hbctraining/scRNA-seq_online/blob/master/lessons/cell_cycle_scoring.md)

[Seurat](https://satijalab.org/seurat/articles/cell_cycle_vignette.html)

Cell cycle regression checking is incorporated in the gencoreSC package. See the 'using-gencoreSC' package for more details on using it in our standard workflow.

## Mapping reference annotations

Datasets with cell-type annotations can be used to estimate cell-types in your
own data. When possible, you should run multiple reference datasets or mapping methods
and compare results. Cell-types in your data may be missing or scarce in a reference,
causing them to be poorly identified when querying. The package has a few
visualization tools to help compare results from multiple references/methods.

### SingleR

SingleR can map metadata from a reference dataset of bulk or single-cell data.
It compares the expression profile (of all genes by default) of the query set to
the reference to find similarities. This can be done on a per-cell level or
using clusters within the query, which uses the aggregate expression profile. 
Since it can be done on a per-cell level, without much need for processing,
it is easy to use SingleR on multiple captures in a single merged object 
without any integration.

[Vignette](https://bioconductor.org/packages/release/bioc/vignettes/SingleR/inst/doc/SingleR.html)
[Github](https://github.com/dviraran/SingleR)

#### Runtime considerations

SingleR expects both the query and reference to be normalized and log-transformed.
You should not use SCTransform data for SingleR since the normalization does 
not seem to be on a per-cell level [(more on this discussion here)](https://github.com/immunogenomics/harmony/issues/41).

The `de.method` should be set to 'wilcox' for single-cell data ([from vignette](https://bioconductor.org/packages/release/bioc/vignettes/SingleR/inst/doc/SingleR.html)).

### Azimuth

Azimuth is built by some of the same people who work on Seurat. They have a web
interface you can use to do annotations, but you lose some ability to manipulate
inputs and outputs. The same functions used in the web GUI can be accessed through
their R library. It is mostly just a wrapper for Seurat's native reference mapping
functions, but with some optimized parameters. 

Azimuth provides some functions to use any annotated Seurat dataset. The benefit
of using Azimuth over using the Seurat functions directly are convenience and 
reproducibility/consistency. 

Azimuth produces two metrics per cell: prediction score and mapping score. 

[Ref](https://azimuth.hubmapconsortium.org/#Mapping%20QC)

**Mapping score** This value from 0 to 1 reflects confidence that this cell is well represented by the reference.
If your query has a cell population not present in the reference, these will likely
have a poor mapping score. 

**Prediction score** Cell prediction scores range from 0 to 1 and reflect the confidence associated with each annotation. Cells with high-confidence annotations (for example, prediction scores > 0.75) reflect predictions that are supported by multiple consistent anchors. 

A cell may have high mapping score but low prediction score if it is split between
two similar clusters of cells, e.g. CD4 central memory and effector memory. 

A cell with high prediction score but low mapping score is likely near a single 
consistent group of cell-types, but not within them. Since no other cell-type neighborhoods
are nearby, there are no conflicting prediction scores. See [Ref](https://azimuth.hubmapconsortium.org/#Mapping%20QC) for more info. 

[Github](https://satijalab.github.io/azimuth/index.html)
[Website](https://azimuth.hubmapconsortium.org/)

#### How it works

```
Here, we introduce “weighted-nearest neighbor” (WNN) analysis, an analytical framework to integrate multiple data types measured within a cell and to obtain a joint definition of cellular state. Our approach is based on an unsupervised strategy to learn cell-specific modality “weights,” which reflect the information content for each modality and determine its relative importance in downstream analyses. 
```
[Ref](https://www.cell.com/cell/fulltext/S0092-8674(21)00583-3)

Briefly (and perhaps naively), it works by 'anchor' cells with similar transcriptional profiles
across the datasets. These anchors are used to normalize differences between the
datasets, which can then be mapped in shared space. Annotations are then predicted
by the annotations of a cell's nearest neighbors from the reference dataset. 

gencoreSC has a helper function to create a custom reference dataset for use
with Azimuth. See the 'using-gencoreSC' vignette for more information.

#### Runtime considerations

```
We have observed that the results (both for visualization and annotation) are very similar when mapping individual batches separately, or combined together. This is because Azimuth can successfully remove batch effects between query and reference cells, even when there are multiple query batches. However, as discussed further below, the results of QC metrics may change. For example, cells from certain batches sometimes receive high mapping scores when the batches are mapped separately but receive low mapping scores when batches are mapped together, as the batch effect represents a source of heterogeneity in the query that is removed by Azimuth.
```

* Reference datasets can be any(?) size, but the web app subsamples to 5000 cells
for resource considerations. In practice, I've used references with 40,000+ cells.
It just takes a little longer, but it might be worth it to preserve niche cell types.

* Creating a reference can be a little tricky. The wrapper function should 
simplify things, but hasn't been super robustly tested. One known consideration
is you need to use at least 50 dimensions for PCA (the default in the wrapper is 
set to 50)

### GencoreSC visualization tools

`extractTopRefMapResults()` will give you a table of the top cell-type predictions
per cluster

`referenceMappingOutcomesFacetPlot()` will give you a more comprehensive look at
all predicted cell-types and the associated prediction scores for each cluster.

## Integration

There is a single wrapper function for running Harmony, STACAS, and Seurat integration
within the gencoreSC package. See the 'using-gencoreSC' vignette for mroe details.
The idea is to have consistent pre-processing for all method so you can compare 
and choose the appropriate one for your study. 

## Demultiplexing hashed captures

[Paper on cell hashing](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-018-1603-1)

[Seurat vignette](https://satijalab.org/seurat/articles/hashing_vignette.html)

Cells from multiple samples can be loaded in the same capture as a cost saving
method. The cells are associated with a sample by ADTs. Seurat has methods
to assign sample names to cells based on the abundance of sample-specific
ADTs. 

HTO information can also be used to feed ground truth data for doublet detection.
See the Doublet Removal section of the vignette for more details. 

HTO data should be separated from other antibodies for the purpose of normalization.

### Within gencoreSC

The helper function `demuxAntibodyData()` serves as a wrapper to Seurat's
`HTODemux()`. See the 'using-gencoreSC' vignette for more details.

# Reference data

We are attempting to aggregate marker genes in a git tracked repo.

`/yerkes-cifs/runs/scrna_seq_ref/marker_genes/`
https://github.com/yerkes-gencore/marker_genes

Other reference datasets live on the server at
`/yerkes-cifs/runs/scrna_seq_ref/`

# Term glossary

Term  | Explanation
----- | -----------
DEG   |   Differentially expressed genes
Soup  |   Ambient RNA from lysed cells
HTO   |   Hash tag oligos
ADT   |   Antibody derived tags
GEM   |   Gel emulsion bead

